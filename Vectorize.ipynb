{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c87fdd-9c0c-498e-8bc5-6a962b75f97d",
   "metadata": {},
   "source": [
    "### 1-Vectorize işlemi nedir? TFIDF vectorizer üzerinden örneklerle açıkladığınız bir markdown oluşturunuz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c316156-4ee2-43dc-a86e-b0b5db837ee6",
   "metadata": {},
   "source": [
    "# Vektörize İşlemi ne demektir ?\n",
    "Makine öğrenmesi modelleri verileri sayısal biçimde işler. Ancak metin, kategorik değer gibi veriler doğrudan kullanılmaz. Bu nedenle **vectorize işlemi**, bu verileri modelin anlayabileceği şekilde **sayısal vektörlere** dönüştürme işlemidir.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea0440-8f90-427c-946a-6e033aa977da",
   "metadata": {},
   "source": [
    "### Neden vektörize işleme gerek duyarız:\n",
    "--> Çünkü Metin gibi veriler string türündedir, matematiksel işlemler yapılamaz ve makine öğrenmesi algoritmaları sayılar girdiler ile çalışır.\n",
    "Vektöre dönüştürme sayesinde bu veriler modelin eğitilmesinde kullanılabilir.(lineer cebirsel optimizasyonlara olanak tanır).\n",
    "Özellikle doğal dil işleme projelerinde olmazsa olmazdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906dc12-75be-41b3-886c-527fb99fd739",
   "metadata": {},
   "source": [
    "#### Vectorize Yöntemleri:\n",
    "- **One-Hot Encoding:** Her kategori için ayrı bir sütun oluşturur. 1 ve 0 ile temsil edilir.\n",
    "- **Count Vectorizer:** Her kelimenin kaç kez geçtiğini sayar ve bileşen olarak kullanır.\n",
    "- **TF-IDF Vectorizer:** Hem kelimenin belge içindeki sıklığını hem de tüm belgelerdeki nadirliğini dikkate alır. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46804f-106c-4ab7-add6-b79b9c5d5b82",
   "metadata": {},
   "source": [
    "## TFIDF vectorizer üzerinden örneklerle açıklayalım :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2eb16-9b9d-4b18-bd5f-d7513cb1c6bb",
   "metadata": {},
   "source": [
    "**TF-IDF (Term Frequency – Inverse Document Frequency)**, bir kelimenin bir belge içinde ne kadar önemli olduğunu gösteren bir sayısal değerdir. Bu yöntem özellikle metin sınıflandırma işlemlerinde çok kullanılır.\n",
    "#### Bileşenler:\n",
    "- **TF (Term Frequency):** Kelimenin, belge içindeki tekrar oranı  \n",
    "- **IDF (Inverse Document Frequency):** Kelimenin tüm belgeler arasında ne kadar az geçtiğini ölçer\n",
    " \n",
    "*terimsel olarak baktıysak örneğimize geçelim...*\n",
    "\n",
    "#### Örnek cümleler:\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "1.\"müzik dinlemek ruhu rahatlatır\"                   \n",
    "2.\"kitap okumak insanı geliştirir\"                 \n",
    "3. \"spor yapmak bedeni güçlendirir\"                  \n",
    "4. \"spor ve müzik birlikte yapılabilir\" \n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "yukarıda 4 cümlemiz var ve bu cümlelerde geçen terimler şu şekilde :\n",
    "\n",
    "['müzik', 'dinlemek', 'ruhu', 'rahatlatır',  'kitap', 'okumak', 'insanı', 'geliştirir',  'spor', 'yapmak', 'bedeni', 'güçlendirir', \n",
    "'ve', 'birlikte', 'yapılabilir']\n",
    "\n",
    "\n",
    "ilk olarak TF halini hesaplayacağız.\n",
    "### 1. TF (Term Frequency)\n",
    "\n",
    "4.'de \"spor\" ve \"müzik\" birer kez geçiyor, toplam kelime sayısı: 5  \n",
    "- TF(spor, 4) = 1 / 5 = 0.2  \n",
    "- TF(müzik, 4) = 1 / 5 = 0.2\n",
    "\n",
    "\n",
    "sonrasında IDF\n",
    "### 2. IDF (Inverse Document Frequency)\n",
    "\n",
    "- “müzik” → 1. ve 4. → geçiyor → IDF = log(4 / 2) ≈ 0.301  \n",
    "- “spor” → 3. ve 4. → geçiyor → IDF = log(4 / 2) ≈ 0.301  \n",
    "- “geliştirir” → sadece 2.’de → IDF = log(4 / 1) ≈ 0.602\n",
    "\n",
    "\n",
    "TF-IDF çarpımı ile skoru öğrenicez\n",
    "### 3. TF-IDF\n",
    "\n",
    "- TF-IDF(müzik, 4) = 0.2 × 0.301 ≈ **0.060**  \n",
    "- TF-IDF(spor, 4) = 0.2 × 0.301 ≈ **0.060**  \n",
    "- TF-IDF(geliştirir, 2) = 1/4 × 0.602 = **0.150**\n",
    "\n",
    "“müzik” ve “spor” iki belgede geçtiği için IDF’leri düşüktür.“geliştirir” gibi nadir kelimeler daha yüksek TF-IDF alır.Bu sayede model, ayırt edici ve bilgi taşıyan kelimelere odaklanabilir.Yorumlarını yapabiliriz bu skorlar ile.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855faada-9246-4feb-b88b-0739c7e831e3",
   "metadata": {},
   "source": [
    "### 2- Son derste geliştirdiğimiz model üzerinde çalışarak skor yükseltmeye çalışınız:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4b3b71-6863-48f1-b0df-7368734e2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b58f60dc-75b0-44e1-82bd-194faf4c6b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
       "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb78dc7a-fe8e-4a85-b428-f91097c3ef53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_num\n",
       "0  Subject: enron methanol ; meter # : 988291\\nth...          0\n",
       "1  Subject: hpl nom for january 9 , 2001\\n( see a...          0\n",
       "2  Subject: neon retreat\\nho ho ho , we ' re arou...          0\n",
       "3  Subject: photoshop , windows , office . cheap ...          1\n",
       "4  Subject: re : indian springs\\nthis deal is to ...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"label_num\"]]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e9563f-a7f2-40b1-8384-82f6d1f9becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b975f468-8c62-4a36-a595-3db64b467822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584541062801932"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri = df[\"text\"]\n",
    "etiket = df[\"label_num\"]\n",
    "\n",
    "veri_egitim, veri_test, etiket_egitim, etiket_test = train_test_split(veri, etiket, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.85 , min_df=2,ngram_range=(1, 2))\n",
    "vektor_egitim = vectorizer.fit_transform(veri_egitim)\n",
    "vektor_test = vectorizer.transform(veri_test)\n",
    "\n",
    "# yukarıda metin verilerimizi makine öğrenmesi algoritmalarının anlayabileceği yani sayısal forma dönüştürmk için TFIDF vectorizer kullandım.\n",
    "# stop_words=\"english\" parametresi kullanarak, İngilizce'deki \"the\", \"is\", \"and\" gibi anlam taşımayan sık kelimeleri filtremiş oldum.\n",
    "# max_df=0.85 çok sık geçen ama anlam taşımayan kelimeleri eledim.Modeli daha ayırt edici kelimelere odakladım.\n",
    "# min_df=2 sadece bir-iki mesajda geçen kelimeleri eledim.Çünkü bu kelimeler genelde çok özel ya da anlamsız kelimeler oluyor ve modele katkı sağlamıyor.\n",
    "# ngram_range=(1, 2) parametresinde tek kelimelerin yanı sıra iki kelimelik kalıpları da dahil ettim.Özellikle spam mesajlarda geçen “free offer”, “click now” gibi ifadeler modelin daha iyi anlamasına yardımcı oluyor.\n",
    "# fit_transform eğitim verisindeki kelimeleri analiz etti ve bunları vektörlere çevirdi.\n",
    "# transform test verisini aynı kelime bilgisiyle vektörleştirdi.\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(vektor_egitim, etiket_egitim)\n",
    "\n",
    "tahmin = model.predict(vektor_test)\n",
    "\n",
    "accuracy_score(etiket_test, tahmin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140eff86-2126-4798-af58-a34a76158a22",
   "metadata": {},
   "source": [
    "#### Yaklaşık olarak doğruluk oranını 0.92'den 0.95 e çıkarmış olduk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf80dc-4bce-4eac-83f2-cf409b0bd49f",
   "metadata": {},
   "source": [
    "##### noktalama vb. ifadelerinde düzenlemensini gerçekleştirip sonrasında vektörizemizi gerçekleştirirsek nasıl bir sonuç alırız bunu da merak ettiğim ve doğruluk oranının artıcağını düşündüm için araştırmasını yaptım ve şu adımları izledim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d1d790-a2c2-47f3-8b1f-8f8b28995dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3c0b5-82a9-4369-8465-9e9e7b20e619",
   "metadata": {},
   "source": [
    "re → regular expressions (düzenli ifadeler) modülüdür.Metinler üzerinde arama, değiştirme, filtreleme gibi işlemleri kolayca yapmanı sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caa5115f-7983-47fd-ab69-f3af5a4eadbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966183574879227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temizle(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "df[\"text_temiz\"] = df[\"text\"].apply(temizle)\n",
    "\n",
    "veri = df[\"text_temiz\"]\n",
    "etiket = df[\"label_num\"]\n",
    "\n",
    "veri_egitim, veri_test, etiket_egitim, etiket_test = train_test_split(veri, etiket, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.85, min_df=2, ngram_range=(1, 2))\n",
    "vektor_egitim = vectorizer.fit_transform(veri_egitim)\n",
    "vektor_test = vectorizer.transform(veri_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(vektor_egitim, etiket_egitim)\n",
    "tahmin = model.predict(vektor_test)\n",
    "\n",
    "accuracy_score(etiket_test, tahmin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60bcdc-f4ae-41a7-b31b-653f92a8d8fd",
   "metadata": {},
   "source": [
    "#### Sonuç olarak, gerçekleştirdiğim metin temizleme işlemi sonrasında modelin doğruluk oranı %92'den %96'ya yükseldi. Bu da yapılan ön işlemenin model performansına olumlu bir katkı sağladığını göstermektedir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07e555-a4b2-46db-aba9-e14040b7a35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
