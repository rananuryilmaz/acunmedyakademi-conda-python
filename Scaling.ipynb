{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597ae4f1-1e81-403a-a0a4-d58e1388ff5f",
   "metadata": {},
   "source": [
    "## ->Scaling (Özellik Ölçekleme) nedir? Nasıl yapılır? Araştırıp markdown dosyası oluşturalım"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8156ca-4742-4a61-9dcf-86aea95da583",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Özellik Ölçekleme (Feature Scaling)\n",
    "\n",
    "Makine öğrenmesinde kullanılan algoritmaların verimli ve doğru sonuç verebilmesi için verinin uygun şekilde ön işlenmesi gerekir. Özellik ölçekleme, veri setindeki sayısal değişkenlerin benzer ölçeklere getirilmesi işlemidir. Özellikle birimler veya büyüklükler çok farklıysa, bazı algoritmalar bu durumdan olumsuz etkilenir. Bu nedenle veri modele verilmeden önce ölçeklenmelidir.\n",
    "\n",
    "## Neden Özellik Ölçekleme Yapılır?\n",
    "\n",
    "Veri setindeki sayısal sütunlar farklı büyüklüklere sahip olabilir. Örneğin bir sütun 0 ile 1 arasında değer alırken, başka bir sütun 0 ile 1000 arasında olabilir. Bu durum, özellikle mesafeye dayalı algoritmalarda hatalı sonuçlara neden olur.\n",
    "\n",
    "Ayrıca bazı optimizasyon algoritmaları (örneğin gradient descent) farklı ölçeklerdeki değişkenleri işlerken yavaş çalışabilir veya doğru şekilde öğrenemez. Aynı şekilde, regularization (L1/L2) gibi tekniklerde büyük değerli değişkenler daha fazla cezaya uğrar.\n",
    "\n",
    "Kısacası:\n",
    "- Tüm özelliklerin aynı ölçekte olması, modelin tüm değişkenlere eşit yaklaşmasını sağlar.\n",
    "- Modelin daha stabil, daha hızlı ve daha doğru öğrenmesini sağlar.\n",
    "\n",
    "## Nasıl Yapılır?\n",
    "\n",
    "Özellik ölçekleme için çeşitli yöntemler vardır. Hangi yöntem seçileceği veri yapısına ve kullanılacak modele göre değişir.\n",
    "\n",
    "### 1. StandardScaler (Z-Score)\n",
    "\n",
    "Verilerin ortalaması 0, standart sapması 1 olacak şekilde dönüştürülür.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e151c-3594-4ae8-a678-1ce74f61edad",
   "metadata": {},
   "source": [
    "### 2. MinMaxScaler\n",
    "Verileri 0 ile 1 aralığına sıkıştırır. Aykırı değerlere duyarlıdır.\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "### 3. RobustScaler\n",
    "Medyan ve çeyrekler arası açıklık (IQR) kullanır. Aykırı değerlere karşı dayanıklıdır.\n",
    "```python\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "### 4. MaxAbsScaler\n",
    "Verileri -1 ile 1 arasına çeker ama negatif-pozitif dengesi bozulmaz. Sıfır merkezlidir.\n",
    "```python\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "### 5. Normalizer\n",
    "Veri satırlarını birim vektör haline getirir. Özellikle metin madenciliğinde veya kosinüs benzerliğinde kullanılır.\n",
    "```python\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2978129-71fb-41c7-be70-fe6e643bf15c",
   "metadata": {},
   "source": [
    "## Hangi Algoritmalar Ölçeklendirmeye Duyarlıdır?\n",
    "\n",
    "Bazı algoritmalar veriler arası mesafeye ya da büyüklüğe göre çalıştığı için ölçeklendirme yapılmadan verimli çalışmaz.\n",
    "\n",
    "**Ölçeklemeye duyarlı olan algoritmalar:**\n",
    "- K-Means\n",
    "- KNN (K En Yakın Komşu)\n",
    "- SVM (Destek Vektör Makineleri)\n",
    "- PCA (Ana Bileşenler Analizi)\n",
    "- Lojistik Regresyon\n",
    "- Yapay Sinir Ağları (Neural Networks)\n",
    "\n",
    "**Ölçekleme gerektirmeyen algoritmalar:**\n",
    "- Karar Ağaçları\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Naive Bayes\n",
    "\n",
    "Bu algoritmalar, verilerin büyüklüğüne değil bölünme kurallarına göre çalıştığı için ölçek farkından etkilenmez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48470f-5ccb-4c34-88af-d64efcc2fb9d",
   "metadata": {},
   "source": [
    "| Durum                                      | Uygun Ölçekleme Yöntemi |\n",
    "| ------------------------------------------ | ----------------------- |\n",
    "| Aykırı değerler varsa                      | RobustScaler            |\n",
    "| Dağılımı bozmadan ölçeklemek isteniyorsa   | StandardScaler          |\n",
    "| Tüm veriler 0-1 arasında olsun isteniyorsa | MinMaxScaler            |\n",
    "| Negatifli-pozitifli değerler varsa         | MaxAbsScaler            |\n",
    "| Satır vektör normu gerekiyorsa             | Normalizer              |\n",
    "\n",
    "**Özellik ölçekleme, birçok makine öğrenmesi algoritması için önemli bir ön işleme adımıdır. Verilerin aynı ölçeğe çekilmesi sayesinde modeller daha adil ve dengeli öğrenme yapar. Hangi yöntemin kullanılacağı veri yapısına ve model türüne göre değişir.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a2f0a-2247-4428-aaa1-473aa73ad207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
